## Variant 1 (my)

[A QR code rendering picture]

It is not just a QR code picture, but a picture printed by a program generated by my Python coding agent. Why taking time implementing it in the end of 2025? Well, with my Embedded Engineering background, and I am always curious to understand the inner workings of a complex system, to understand how they are designed, and to see their limits. I am considering it as a valid answer.

Not long ago, I was reading through the preview of "Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems" book by [Antonio Gulli](https://www.linkedin.com/in/searchguy/). Design Patterns demonstrate architecture ideas in a ready-to-consume way, that's why the book immediately caught my attention.  

A "Goal Setting and Monitoring" pattern had an example code written by [Mahtab Syed](https://www.linkedin.com/in/mahtabsyed/). The code demonstrated a simple agent with a feedback loop, involving Coder and Reviewer sub-agents, able to complete simple coding tasks. The end result is a simple Python program designed to solve some basic task.

I spent some past weeks improving from this example and creating this [toy-coding-agent](https://github.com/avlk/toy-coding-agent), testing multiple ideas while keeping the project educational. The project demonstrates the design of a coding agent using bare LLM prompts, e.g. no complex sub-agents, just plain LLM calls. 

It is set up to solve 5 pre-configured tasks in Python: solve a classical 8-queens problem, 3d-render a ball over a surface, design and implement a C-like language interpreter, render a barcode and render a QR code. It is also an experimenters workbench to test different approaches and models. Feel free to modify it and create new tasks.

The project page on Github: https://github.com/avlk/toy-coding-agent 
Sample code generated by the agent is here: https://github.com/avlk/toy-coding-agent/releases/download/solutions/toy-coding-agent-solutions.zip



## Variant 2 (AI + me)

[A QR code rendering picture]

This is a QR code saying "Agentic AI", generated by a Python program written by my own coding agent. Why spend time on this in 2025? Out of curiosity. With my Embedded Engineering background, I’m always eager to see how things work under the hood and where their limits lie.

Recently, I was inspired by the preview of ["Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems"](https://www.linkedin.com/posts/searchguy_agenticai-designpatterns-ai-activity-7351622833136906241-GPiR/) by [Antonio Gulli](https://www.linkedin.com/in/searchguy/). I am a big fan of Design Patterns, as they demonstrate architecture ideas in a ready-to-consume way, hence the book immediately caught my attention.

One example, by [Mahtab Syed](https://www.linkedin.com/in/mahtabsyed/), showed a simple agent with a feedback loop—Coder and Reviewer sub-agents solving coding tasks (chapter "Goal Setting and Monitoring"). The end result is a Python program designed to solve some basic task.

Building on that, I created [toy-coding-agent](https://github.com/avlk/toy-coding-agent), an educational project that uses only LLM prompts (no complex sub-agents) to solve classic programming challenges. It’s a educational workbench for experimenting with agentic design patterns and LLM tools, focusing on transparency and modifiability. The next improvement step would be using a multi-agentic system and an MCP to access the code, but that's beyond the scope of this example.

The agent initially tackles five tasks: solve a classical 8-queens problem, 3D-render a ball over a surface, design and implement a C-like language interpreter, render a barcode, and render a QR code (as you see in the picture). Feel free to explore, modify, or add your own tasks!

Project and description on Github: https://github.com/avlk/toy-coding-agent  
Sample code generated by the agent: https://github.com/avlk/toy-coding-agent/releases/download/solutions/toy-coding-agent-solutions.zip

Check it out, try it, or share your thoughts!


The next improvement step would be using a multi-agentic system and an MCP to access the code, but that's beyond the scope of this example. Write me if you would like to see a follow-up example with more advanced techniques in place.


## Linkedin variant

This is a QR code saying "Agentic AI", generated by a Python program written by my own coding agent. Why spend time on this in 2025? Out of curiosity. With my Embedded Engineering background, I’m always eager to see how things work under the hood and where their limits lie.



Recently, I was inspired by the preview of the book "Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems" by Antonio Gulli. I am a big fan of Design Patterns, as they demonstrate architecture ideas in a ready-to-consume way, and the book immediately caught my attention.



One example, by Mahtab Syed, showed a simple agent with a feedback loop—Coder and Reviewer sub-agents solving coding tasks (Chapter "Goal Setting and Monitoring"). The result is a Python program designed to solve the task.



Building on that, I created a toy-coding-agent, an educational project that uses only LLM prompts (no complex sub-agents) to solve classic programming challenges. It’s a workbench for experimenting with agentic design patterns and LLM tools, focusing on transparency and modifiability.



The agent initially tackles five tasks: solve a classical 8-queens problem, 3D-render a ball over a surface, design and implement a C-like language interpreter, render a barcode, and render a QR code (as you see in the picture). 



Project and description on Github: https://github.com/avlk/toy-coding-agent 

Sample code generated by the agent: https://github.com/avlk/toy-coding-agent/releases/download/solutions/toy-coding-agent-solutions.zip

The book: https://www.linkedin.com/posts/searchguy_agenticai-designpatterns-ai-activity-7351622833136906241-GPiR/



Check it out, try it, modify, add your own tasks, or share your thoughts!